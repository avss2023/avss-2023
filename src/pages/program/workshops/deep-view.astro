---
import { Image } from "@astrojs/image/components";
---

<h1 id="workshops-1">Workshops 1</h1>
<h2
  id="3rd-workshop-and-challenge-on-deepview-global-multi-target-visual-surveillance-based-on-real-time-large-scale-analysis"
>
  3rd Workshop and Challenge on Deepview: Global Multi-Target Visual
  Surveillance Based on Real-Time Large-Scale Analysis
</h2>
<p><strong>Organized by: Moongu Jeon (GIST)</strong></p>
<p>
  <a
    href="/Global+Multi+Target+Visual+Surveillance+Based+on+Real+Time+Large+Scale+Analysis.pdf"
    >Workshop Description File (PDF)</a
  >
</p>
<h3 id="introduction">Introduction</h3>
<p>
  With the development of artificial intelligence technology, the demand for
  smart development of living spaces has increased. Smart cities are one of
  these demands, including surveillance systems based on large-scale camera
  networks. This system can provide various services, such as accurate traffic
  measurements and intelligent surveillance services. These services, which
  operate in real-time on large camera networks, include many sub-modules like
  object detection, tracking, re-identification, and human behavior analysis.
  For constructing complete visual surveillance systems, some issues like
  illumination changes, dynamic backgrounds, poor data quality, and the lack of
  high-quality models should be solved. From this workshop, professional
  speakers will present their research experience and opinions about the future.
</p>
<p>
  Data lack is one of these problems. Real human data or special objects like
  military weapons are usually hard to gather due to legal and security issues.
  Also, collecting large datasets from a real environment is very costly. One of
  the solutions for this problem is synthetic data. Synthetic data is very cheap
  and collected quickly by the simulation engine. This proposal provides the
  challenge plan to utilize these synthetic data.
</p>
<h3 id="workshop-topics">Workshop Topics</h3>
<p>
  We embrace the most advanced deep learning systems, meanwhile being open to
  classical physically grounded models and feature engineering, as well as any
  well-motivated combination of the two streams. We will invite speakers with
  professional knowledge and experience about the following topics:
</p>
<ul>
  <li>Robust recognition and detection in the surveillance videos</li>
  <li>
    Large-scale multi-camera multi-object application (detection, tracking,
    reidentification, and others)
  </li>
  <li>2D/3D pose estimation in the surveillance videos</li>
  <li>One/few-shot learning in the unconstrained surveillance scenarios</li>
  <li>Anomaly detection in the surveillance videos</li>
  <li>Human behavior analysis and recognition in the surveillance videos</li>
  <li>Generation of visual data for surveillance analysis system</li>
  <li>Privacy-preserving visual learning</li>
  <li>Applications and systems for security and safe</li>
</ul>
<h3 id="challenge-topics">Challenge Topics</h3>
<p>
  We will organize 1 or 2 challenges. The task of the first challenge is object
  detection in synthetic aerial imagery. Participants will get training(50k )
  and testing datasets, including very small military weapons and objects. Also,
  the background of the provided dataset will show various environments like
  sea, forest, and mountain. The evaluation metric will be a traditional metric
  for object detection, mAP. The task of the second challenge is domain transfer
  from synthetic data to real data. Participants should collect unpaired real
  data and transfer synthetic data to real data using various generative models
  like GAN and diffusion models. We will request short papers(2-3 pages) or
  regular papers with their problem-solving process to evaluate these submitted
  methods.
</p>
<Image
  src="dataset-overview.png"
  alt="Dataset Overview"
  width={672}
  height={168}
  format="webp"
/>
<h3 id="expected-schedule">Expected Schedule</h3>
<p>
  A tentative program of the workshop would follow the classic structure of AVSS
  workshop and challenge programs.
</p>

<table>
  <thead><tr><th>Program</th><th>Time</th></tr></thead><tbody
    ><tr><td>Opening Remarks</td><td>13:00 - 13:15</td></tr><tr
      ><td>Invited Talk 1</td><td>13:15 - 14:00</td></tr
    ><tr><td>Invited Talk 2</td><td>14:00 - 14:45</td></tr><tr
      ><td>Invited Talk 3</td><td>14:45 - 15:30</td></tr
    ><tr><td>Coffee Break</td><td>15:30 - 16:00</td></tr><tr
      ><td>The First Challenge Presentation</td><td>16:00 - 16:45</td></tr
    ><tr><td>Coffee Break</td><td>16:45 - 17:00</td></tr><tr
      ><td>The Second Challenge Presentation</td><td>17:00 - 17:45</td></tr
    ><tr><td>Awards and Closing Remarks</td><td>17:45 - 18:00</td></tr></tbody
  >
</table>
<h3 id="program-description">Program Description</h3>
<p>
  We will invite speaker three or more speakers, and they will present for about
  45min. The topic is related to computer vision and intelligent surveillance
  systems. Challenges will be opened in public challenge management systems like
  Kaggle. Whole researchers can join these challenges and make teams. We will
  encourage them to share source code and know-how. It will promote our
  challenge to make improved results. The top 3 participants of each challenge
  will present their method for about 15 min. We will provide $1000 - $2000
  awards for each challenge.
</p>
<h3 id="important-dates">Important Dates</h3>
<ul>
  <li>Challenge Site Open: August 1, 2023</li>
  <li>Challenge Start: September 1, 2023</li>
  <li>Challenge End: October 10, 2023</li>
  <li>Workshop Date: November 6, 2023</li>
</ul>
<h3 id="organized-by">Organized by</h3>
<p>
  <strong>Moongu Jeon (GIST):</strong> Moongu Jeon received the B.S. degree in architectural
  engineering from Korea University, Seoul, South Korea, in 1988, and the M.S. and
  Ph.D. degrees in computer science and scientific computation from the University
  of Minnesota, Minneapolis, MN, USA, in 1999 and 2001, respectively. As the masterâ€™s
  degree researcher, he was involved in optimal control problems with the University
  of California at Santa Barbara, Santa Barbara, CA, USA, from 2001 to 2003, and
  then moved to the National Research Council of Canada, where he was involved in
  the sparse representation of high-dimensional data and the image processing, until
  July 2005. In 2005, he joined the Gwangju Institute of Science and Technology,
  Gwangju, South Korea, where he is currently a Full Professor with the School of
  Electrical Engineering and Computer Science. He has served as a editor of Information
  Sciences. His current research interests include machine learning, computer vision,
  and artificial intelligence.
</p>
<ul>
  <li>E-mail: <a href="mailto:mgjeon@gist.ac.kr">mgjeon@gist.ac.kr</a></li>
</ul>
<p>
  <strong>Yuseok Bae (ETRI):</strong> Yuseok Bae received the B.S. and M.S. degrees
  in computer science from Kyungpook National University, Korea, in 1995 and 1997
  respectively. He is currently a principal researcher with the Visual Intelligence
  Research Section at the Electronics and Telecommunications Research Institute (ETRI),
  where he has been involved in various projects such as distributed computing, home
  network middleware, IPTV middleware, big data analytics, and visual artificial
  intelligence since 1997. He received his Ph.D. degree in computer science from
  Kyungpook National University in 2011. His research interests include distributed
  computing, computer vision, deep learning, and visual artificial intelligence.
</p>
<ul>
  <li>E-mail: <a href="mailto:baeys@etri.re.kr">baeys@etri.re.kr</a></li>
</ul>
<p>
  <strong>Jinyoung Moon (ETRI):</strong> Jinyoung Moon received her M.S. degree in
  Computer Science and Ph.D. in Industrial Systems Engineering from the Korea Advanced
  Institute of Science and Technology (KAIST), Daejeon, Rep. of Korea, in 2002 and
  2018, respectively. Since 2002, she has been working with the Visual Intelligence
  Research Section, the Artificial Intelligence Research Laboratory, the Electronics
  and Telecommunications Research Institute (ETRI), Daejeon, Rep. of Korea. Since
  2019, she has also been with the ICT department, the University of Science and
  Technology (UST), where she is currently an Assistant Professor. Her main research
  interests include action recognition, human action localization and detection,
  temporal moment localization, video QA, and representation learning for vision
  and language.
</p>
<ul>
  <li><a href="mailto:jymoon@etri.re.kr">jymoon@etri.re.kr</a></li>
</ul>
<h3 id="acknowledgements">Acknowledgements</h3>
<p>
  This work is supported by Institute of Information &amp; Communications
  Technology Planning &amp; Evaluation (IITP) grant funded by the Korea
  government (MSIT) (AI National Strategy Project (No.2014-3-00077) and
  Development of High Performance Visual BigData Discovery Platform for
  Large-Scale Realtime Data Analysis (No.2014-3-00123)).
</p>
