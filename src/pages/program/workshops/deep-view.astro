---
import { Image } from "@astrojs/image/components";
import Layout from "../../../layouts/Layout.astro";
import MainHeader from "../../../components/Tags/MainHeader.astro";
import Section from "../../../components/Tags/Section.astro";
import Heading3 from "../../../components/Tags/Heading3.astro";
import Paragraph from "../../../components/Tags/Paragraph.astro";
import Heading4 from "../../../components/Tags/Heading4.astro";
import UList from "../../../components/Tags/UList.astro";
import List from "../../../components/Tags/List.astro";
import type { Row } from "../../../components/Tags/Table.astro";
import Table from "../../../components/Tags/Table.astro";

const tableData: Row[] = [
  { items: ["Program", "Time"], title: true },
  { items: ["Opening Remarks", "13:00 - 13:15"] },
  { items: ["Invited Talk 1", "13:15 - 14:00"] },
  { items: ["Invited Talk 2", "4:00 - 14:45"] },
  { items: ["Invited Talk 3", "14:45 - 15:30"] },
  { items: ["Coffee Break", "15:30 - 16:00"] },
  { items: ["The First Challenge Presentation", "16:00 - 16:45"] },
  { items: ["Coffee Break", "16:45 - 17:00"] },
  { items: ["The Second Challenge Presentation", "17:00 - 17:45"] },
  { items: ["Awards and Closing Remarks", "17:45 - 18:00"] },
];
---

<Layout title="Program :: AVSS2023">
  <MainHeader metaTitle="Program" title="Workshops" />
  <Section>
    <Heading3
      title="3rd Workshop and Challenge on Deepview: Global Multi-Target Visual Surveillance Based on Real-Time Large-Scale Analysis"
    />
    <Paragraph><strong>Organized by: Moongu Jeon (GIST)</strong></Paragraph>
    <Paragraph>
      <a
        class="fancy"
        href="/Global+Multi+Target+Visual+Surveillance+Based+on+Real+Time+Large+Scale+Analysis.pdf"
        >Workshop Description File (PDF)</a
      >
    </Paragraph>
    <Heading4 title="Introduction" />
    <Paragraph>
      With the development of artificial intelligence technology, the demand for
      smart development of living spaces has increased. Smart cities are one of
      these demands, including surveillance systems based on large-scale camera
      networks. This system can provide various services, such as accurate
      traffic measurements and intelligent surveillance services. These
      services, which operate in real-time on large camera networks, include
      many sub-modules like object detection, tracking, re-identification, and
      human behavior analysis. For constructing complete visual surveillance
      systems, some issues like illumination changes, dynamic backgrounds, poor
      data quality, and the lack of high-quality models should be solved. From
      this workshop, professional speakers will present their research
      experience and opinions about the future.
    </Paragraph>
    <Paragraph>
      Data lack is one of these problems. Real human data or special objects
      like military weapons are usually hard to gather due to legal and security
      issues. Also, collecting large datasets from a real environment is very
      costly. One of the solutions for this problem is synthetic data. Synthetic
      data is very cheap and collected quickly by the simulation engine. This
      proposal provides the challenge plan to utilize these synthetic data.
    </Paragraph>
    <Heading4 title="Workshop Topics" />
    <Paragraph>
      We embrace the most advanced deep learning systems, meanwhile being open
      to classical physically grounded models and feature engineering, as well
      as any well-motivated combination of the two streams. We will invite
      speakers with professional knowledge and experience about the following
      topics:
    </Paragraph>
    <UList>
      <List>Robust recognition and detection in the surveillance videos</List>
      <List>
        Large-scale multi-camera multi-object application (detection, tracking,
        reidentification, and others)
      </List>
      <List>2D/3D pose estimation in the surveillance videos</List>
      <List>
        One/few-shot learning in the unconstrained surveillance scenarios
      </List>
      <List>Anomaly detection in the surveillance videos</List>
      <List>
        Human behavior analysis and recognition in the surveillance videos
      </List>
      <List>Generation of visual data for surveillance analysis system</List>
      <List>Privacy-preserving visual learning</List>
      <List>Applications and systems for security and safe</List>
    </UList>
    <Heading4 title="Challenge Topics" />
    <Paragraph>
      We will organize 1 or 2 challenges. The task of the first challenge is
      object detection in synthetic aerial imagery. Participants will get
      training(50k ) and testing datasets, including very small military weapons
      and objects. Also, the background of the provided dataset will show
      various environments like sea, forest, and mountain. The evaluation metric
      will be a traditional metric for object detection, mAP. The task of the
      second challenge is domain transfer from synthetic data to real data.
      Participants should collect unpaired real data and transfer synthetic data
      to real data using various generative models like GAN and diffusion
      models. We will request short papers(2-3 pages) or regular papers with
      their problem-solving process to evaluate these submitted methods.
    </Paragraph>
    <Image
      src="dataset-overview.png"
      alt="Dataset Overview"
      width={672}
      height={168}
      format="webp"
    />
    <Heading4 title="Expected Schedule" />
    <Paragraph>
      A tentative program of the workshop would follow the classic structure of
      AVSS workshop and challenge programs.
    </Paragraph>

    <Table rows={tableData} />

    <Heading4 title="Program Description" />
    <Paragraph>
      We will invite speaker three or more speakers, and they will present for
      about 45min. The topic is related to computer vision and intelligent
      surveillance systems. Challenges will be opened in public challenge
      management systems like Kaggle. Whole researchers can join these
      challenges and make teams. We will encourage them to share source code and
      know-how. It will promote our challenge to make improved results. The top
      3 participants of each challenge will present their method for about 15
      min. We will provide $1000 - $2000 awards for each challenge.
    </Paragraph>
    <Heading4 title="Important Dates" />
    <UList>
      <List>Challenge Site Open: August 1, 2023</List>
      <List>Challenge Start: September 1, 2023</List>
      <List>Challenge End: October 10, 2023</List>
      <List>Workshop Date: November 6, 2023</List>
    </UList>
    <Heading4 title="Organized by" />
    <Paragraph>
      <strong>Moongu Jeon (GIST):</strong> Moongu Jeon received the B.S. degree in
      architectural engineering from Korea University, Seoul, South Korea, in 1988,
      and the M.S. and Ph.D. degrees in computer science and scientific computation
      from the University of Minnesota, Minneapolis, MN, USA, in 1999 and 2001, respectively.
      As the masterâ€™s degree researcher, he was involved in optimal control problems
      with the University of California at Santa Barbara, Santa Barbara, CA, USA,
      from 2001 to 2003, and then moved to the National Research Council of Canada,
      where he was involved in the sparse representation of high-dimensional data
      of Science and Technology, Gwangju, South Korea, where he is currently a Full
      and the image processing, until July 2005. In 2005, he joined the Gwangju Institute
      Professor with the School of Electrical Engineering and Computer Science. He
      has served as a editor of Information Sciences. His current research interests
      include machine learning, computer vision, and artificial intelligence.
    </Paragraph>
    <UList>
      <List>
        E-mail: <a class="fancy" href="mailto:mgjeon@gist.ac.kr"
          >mgjeon@gist.ac.kr</a
        >
      </List>
    </UList>
    <Paragraph>
      <strong>Yuseok Bae (ETRI):</strong> Yuseok Bae received the B.S. and M.S. degrees
      in computer science from Kyungpook National University, Korea, in 1995 and
      1997 respectively. He is currently a principal researcher with the Visual Intelligence
      Research Section at the Electronics and Telecommunications Research Institute
      (ETRI), where he has been involved in various projects such as distributed
      computing, home network middleware, IPTV middleware, big data analytics, and
      visual artificial intelligence since 1997. He received his Ph.D. degree in
      computer science from Kyungpook National University in 2011. His research interests
      include distributed computing, computer vision, deep learning, and visual artificial
      intelligence.
    </Paragraph>
    <UList>
      <List>
        E-mail: <a class="fancy" href="mailto:baeys@etri.re.kr"
          >baeys@etri.re.kr</a
        >
      </List>
    </UList>
    <Paragraph>
      <strong>Jinyoung Moon (ETRI):</strong> Jinyoung Moon received her M.S. degree
      in Computer Science and Ph.D. in Industrial Systems Engineering from the Korea
      Advanced Institute of Science and Technology (KAIST), Daejeon, Rep. of Korea,
      in 2002 and 2018, respectively. Since 2002, she has been working with the Visual
      Intelligence Research Section, the Artificial Intelligence Research Laboratory,
      the Electronics and Telecommunications Research Institute (ETRI), Daejeon,
      Rep. of Korea. Since 2019, she has also been with the ICT department, the University
      of Science and Technology (UST), where she is currently an Assistant Professor.
      Her main research interests include action recognition, human action localization
      and detection, temporal moment localization, video QA, and representation learning
      for vision and language.
    </Paragraph>
    <UList>
      <List>
        <a class="fancy" href="mailto:jymoon@etri.re.kr">jymoon@etri.re.kr</a>
      </List>
    </UList>
    <Heading4 title="acknowledgements">Acknowledgements</Heading4>
    <Paragraph>
      This work is supported by Institute of Information &amp; Communications
      Technology Planning &amp; Evaluation (IITP) grant funded by the Korea
      government (MSIT) (AI National Strategy Project (No.2014-3-00077) and
      Development of High Performance Visual BigData Discovery Platform for
      Large-Scale Realtime Data Analysis (No.2014-3-00123)).
    </Paragraph>
  </Section>
</Layout>
