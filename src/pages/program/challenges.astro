---
---

<h1 id="challenges">Challenges</h1>
<h2 id="cross-view-multi-object-tracking-in-diverse-open-scenes">
  Cross-view Multi-object Tracking in DIVerse Open Scenes
</h2>
<h3 id="introduction">Introduction</h3>
<p>
  Cross-view multi-object tracking is a challenging problem in computer vision
  that involves tracking multiple objects of interest across multiple camera
  views. The goal is to associate object detections across different views and
  time frames, and to maintain the identity of each object throughout the
  tracking process. Interested participants are invited to apply their
  approaches and methods on a novel cross-view multi-object tracking dataset <strong
    >DIVOTrack</strong
  > being made available by the challenge organizers. We collect data in 15 different
  realÂ­world scenarios, including indoor and outdoor public scenes. The dataset is
  split into development data with a training set, testing set, and challenge set.
  Each of them contains 5 different real-world scenarios, including indoor and outdoor
  public scenes. The duration of each video is about 1 minute at 30FPS. All the sequences
  are captured by using three moving cameras and are manually synchronized. There
  are both moving dense crowds and sparse pedestrians in outdoor scenes. The surrounding
  environment of outdoor scenes is diverse, including streets, vehicles, buildings,
  and public infrastructures. Meanwhile, the indoor scene comes from a large shopping
  mall, with a more complicated and severe occlusion of the crowd than the outdoor
  environment. The development data includes original video clips, object bounding
  boxes, and global id for each object. The organizers will support the evaluation
  and scoring the result of the challenge set. The results of each scene has 3 txt
  files. The txt file format is <code>frame_id</code>
  <code>person_id</code>
  <code>Ix</code>
  <code>ly</code>
  <code> w</code>
  <code> h</code> , <strong>fid</strong> is frame id, <strong>pid</strong> is person
  id, <strong>Ix</strong> is the x coordinate of the lefttop position, <strong
    >ly</strong
  > is the y coordinate of the lefttop position, <strong>w</strong> and <strong
    >h</strong
  > are the width and height of each person box. The participants can download the<strong
    >DIVOTrack</strong
  > from <a href="https://github.com/shengyuhao/DIVOTrack#dataset-downloads"
    >https://github.com/shengyuhao/DIVOTrack#dataset-downloads</a
  > , and use the evaluation protocol from<a
    href="https://github.com/shengyuhao/DIVOTrack/tree/main/MOTChallengeEvalKit_cv_test/cv_test"
    >https://github.com/shengyuhao/DIVOTrack/tree/main/MOTChallengeEvalKit_cv_test/cv_test</a
  >
</p>
<h3 id="the-rules-for-participation">The rules for participation</h3>
<p>
  The competition is open to everyone. But the members from the teams of the
  organizers cannot join. All teams should mailed the license for using <strong
    >DIVOTrack</strong
  > to shengyuhao (<a href="mailto:shengyuhao@zju.edu.cn"
    >shengyuhao@zju.edu.cn</a
  >). <strong
    >The top 3 teams will be invited to give a presentation, including methods
    and experimental results.</strong
  >
</p>
<p>
  Note: Please use your <strong>institutional</strong> email to register for the
  competition, otherwise the registration will not be approved.
</p>
<h3 id="the-criteria-that-will-be-used-to-evaluate-the-submitted-entries">
  The criteria that will be used to evaluate the submitted entries
</h3>
<p>
  The evaluation should be user-friendly and convenient for participants. It
  should also be fair and safe to be hacked. We designed detailed rules as
  follows:
</p>
<ul>
  <li>We will limit the number of submissions each day to 1.</li>
  <li>
    Run submission files should be emailed directly to shengyuhao (<a
      href="mailto:shengyuhao@zju.edu.cn">shengyuhao@zju.edu.cn</a
    >). The ranking will be updated on the scoreboard.
  </li>
  <li>
    The top 3 teams in the final scoreboard need to send their programs to the
    organizers. The programs are being run to reproduce their results.
  </li>
</ul>
<h3 id="the-team-that-will-run-the-challenge">
  The team that will run the challenge
</h3>
<p>
  The team running the challenge from Zhejiang University - University of
  Illinois Urbana-Champaign Institute. The team would be responsible for
  creating the challenge dataset, defining the evaluation metrics and rules, and
  providing support and guidance to the participants throughout the challenge.
</p>
<h3 id="important-dates">Important dates</h3>
<ul>
  <li>Baseline release: Available now</li>
  <li>
    Training and Testing dataset release: Available now, 2023 [Available now
    after submitting the data agreement from located <strong>HERE</strong>]
  </li>
  <li>Challenge set release: May 15, 2023</li>
  <li>Submissions of solutions to organizers: October 24, 2023</li>
  <li>Competition results announcement: November 1, 2023</li>
  <li>Grand Challenge at AVSS 2023: TBD</li>
</ul>
